<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>From Head to Tail: Towards Balanced Representation in Large Vision-Language Models through Adaptive Data Calibration</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href= "https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
<!--  <link rel="stylesheet"-->
<!--        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">-->
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/leaderboard.css">
  <link rel="icon" href="./static/images/reward3.png">

  <script type="text/javascript" src="static/js/sort-table.js" defer></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/explorer-index.js"></script>
  <script src="./static/js/question_card.js"></script>

  <script src="./static/js/leaderboard_testmini.js"></script>
  <script src="./visualizer/data/data_public.js" defer></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://github.com/ssmisya">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://github.com/ssmisya/MHR">
            MHR
          </a>
          <a class="navbar-item" href="https://prmbench.github.io/">
            PRMBench
          </a>
          <a class="navbar-item" href="https://github.com/zhaochen0110/OpenThinkIMG">
            OpenThinkImG
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">From Head to Tail: Towards Balanced Representation in Large Vision-Language Models through Adaptive Data Calibration</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://github.com/ssmisya">Mingyang Song</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=rT3hqdcAAAAJ&hl=zh-CN">Xiaoye Qu</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://sites.harvard.edu/jzhou/">Jiawei Zhou</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://ych133.github.io/">Yu Cheng</a><sup>4</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Fudan University,</span>
            <span class="author-block"><sup>2</sup>Shanghai AI Laboratory,</span>
            <span class="author-block"><sup>3</sup>Stony Brook University,</span>
            <span class="author-block"><sup>4</sup>The Chinese University of Hong Kong</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block" style="color: red;">CVPR 2025</span>
          </div>


          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2503.12821"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2503.12821"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/ssmisya/robustLMM"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <figure class="image is-fullwidth">
        <img src="./static/images/main_fig.jpg" alt="Teaser Image">
      </figure>
      <h2 class="subtitle has-text-centered">
        The overview of our <span class="dnerf"><strong>Adaptive Data Refinement Framework (ADR)</strong></span>.<br>
        <strong>(a)</strong> In the Analyzing Stage, we first extract<span style="color: blue;"> <em>tokens, objects, co-occurrences, and interrogations</em></span> from the training instances, then construct corresponding distribution using a reverse-indexed mapping.<br>
        <strong>(b)</strong>  In the Data Rebalancing stage, we analyze the optimizing direction and adaptively rebalance the redundant data based on the entity distribution identified in the Analyzing stage.<br>
        <strong>(c)</strong>  Finally, in the Data Synthesis stage, we utilize <span style="color: blue;">DDPM</span> and the latent representations of scarce image instances to synthesize the underrepresented data.<br>

<!--          An overview of our <span class="dnerf"><strong>PRMBench</strong>. The left part illustrates our data curation procedure. In the right part of the figure, we showcase demonstrations of our evaluation subjects and the relative performance of tested models, with-->
<!--          <span style="background-color: rgb(201, 229, 221); padding: 0.1em;">green</span>,-->
<!--          <span style="background-color: rgb(255, 243, 213); padding: 0.1em;">yellow</span>, and-->
<!--          <span style="background-color: rgb(211, 209, 209); padding: 0.1em;">gray</span> boxes indicating <em>simplicity</em>, <em>soundness</em>, and <em>sensitivity</em> respectively, where-->
<!--          <span style="background-color: rgb(224, 146, 124); padding: 0.1em;">red</span> circles represent erroneous steps and-->
<!--          <span style="background-color: rgb(126, 176, 149); padding: 0.1em;">green</span> circles indicate correct regular steps.-->

      </h2>
    </div>
  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Large Vision-Language Models (LVLMs) have achieved significant progress in combining visual comprehension with language generation. Despite this success, the training data of LVLMs still suffers from Long-Tail (LT) problems, where the data distribution is highly imbalanced.
            Previous works have mainly focused on traditional VLM architectures, i.e., CLIP or ViT, and specific tasks such as recognition and classification. Nevertheless, the exploration of LVLMs (e.g., LLaVA) and more general tasks (e.g., Visual Question Answering and Visual Reasoning) remains under-explored.
            In this paper, we first conduct an in-depth analysis of the LT issues in LVLMs and identify two core causes: the overrepresentation of head concepts and the underrepresentation of tail concepts.
            Based on the above observation, we propose an <span class="dnerf">Adaptive Data Refinement Framework (ADR)</span>, which consists of two stages: <span class="dnerf">Data Rebalancing (DR)</span> and <span class="dnerf">Data Synthesis (DS)</span>.
            In the DR stage, we adaptively rebalance the redundant data based on entity distributions, while in the DS stage, we leverage Denoising Diffusion Probabilistic Models (DDPMs) and scarce images to supplement underrepresented portions.
            Through comprehensive evaluations across eleven benchmarks, our proposed ADR effectively mitigates the long-tail problem in the training data, improving the average performance of LLaVA 1.5 relatively by <span style="color: red;">4.36%</span>, without increasing the training data volume.
          </p>

        </div>
      </div>
    </div>
    <!--/ Abstract. -->



<!--    <section class="section">-->
<!--      <div class="container">-->

<!--        <div class="columns is-centered">-->
<!--          <div class="column is-full has-text-centered content">-->


<!--  </div>-->
<!--  </div>-->

<!--  </div>-->
<!--</section>-->

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{song2025head,
  title={From head to tail: Towards balanced representation in large vision-language models through adaptive data calibration},
  author={Song, Mingyang and Qu, Xiaoye and Zhou, Jiawei and Cheng, Yu},
  journal={arXiv preprint arXiv:2503.12821},
  year={2025}
}</code></pre>
  </div>
</section>


    <section>
      <div class="section" id="org-banners" style="display:flex">
        <a href="https://www.fudan.edu.cn/" target="_blank" rel="external">
          <img class="center-block org-banner" style="height:200px; object-fit:contain;" src="static/images/fdu.jpg">
        </a>
        <a href="https://www.shlab.org.cn/" target="blank" class="ext-link">
          <img class="center-block org-banner" style="height:200px; object-fit:contain;" src="static/images/ailab.jpg">
        </a>
        <a href="https://www.stonybrook.edu/" target="_blank" rel="external">
          <img class="center-block org-banner" style="height:200px; object-fit:contain;" src="static/images/stu.jpg">
        </a>
        <a href="https://www.cuhk.edu.hk/chinese/" target="_blank" rel="external">
          <img class="center-block org-banner" style="height:200px; object-fit:contain;" src="static/images/cuhk.jpg">
        </a>
      </div>
    </section>


<footer class="footer">
  <div class="container">
    <div id="visitor-map" style="width: 300px; height: 300px; overflow: hidden; margin: 0 auto;">
      <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=uXX9ttEyvwWpg_VNSd3nV7rjj5YP5PAPRwBbVV8VIs8'></script>
    </div>

    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is adapted from <a href="https://nerfies.github.io/">Nerfies</a> and <a href="https://mathvista.github.io/">Mathvista</a>, licensed under a <a rel="license"
                                                                                                                       href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
